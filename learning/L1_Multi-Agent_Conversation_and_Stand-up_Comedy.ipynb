{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [项目在线代码](https://github.com/ksm26/AI-Agentic-Design-Patterns-with-AutoGen/blob/main/L1_Multi-Agent_Conversation_and_Stand-up_Comedy.ipynb)\n",
    "### [视频地址](https://www.bilibili.com/video/BV1WJ4m137dk/?spm_id_from=333.788.videopod.episodes&vd_source=1d3a7b81d826789081d8b6870d4fff8e&p=2)\n",
    "### [文档](https://microsoft.github.io/autogen/0.2/docs/Getting-Started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![attachment:image.png](https://github.com/ksm26/AI-Agentic-Design-Patterns-with-AutoGen/blob/main/images/l1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/project/KG_Assist_LLM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "  {\n",
    "    \"model\": \"qwen2.5:72b-instruct-q4_0\",\n",
    "    \"base_url\": \"http://192.168.28.5:11434/v1\",\n",
    "    \"api_key\": \"ollama\",\n",
    "    \"price\": [0, 0], \n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用openai本地"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://192.168.28.5:8178/v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"qwen\",\n",
    "        \"api_key\": \"sk-Z9IT6XTbuhNqeWeQwtFj5vlM1NRXsvQ59XObmYU4UIzosvD5\",\n",
    "        \"api_type\": \"openai\",\n",
    "        \"base_url\": \"http://192.168.28.5:8178/v1\",\n",
    "        \"n\": 1,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"price\": [0, 0], \n",
    "        \"default_headers\": {\n",
    "            \"Content-types\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer xxxx\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用 openai-hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_list = [\n",
    "#     {\n",
    "#         \"model\": \"gpt-3.5-turbo\",\n",
    "#         \"api_key\": \"hk-xxx\", # your api key\n",
    "#         \"api_type\": \"openai\",\n",
    "#         \"base_url\": \"https://api.openai-hk.com/v1\",\n",
    "#         \"api_type\": \"openai\",\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config={\"config_list\": config_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\", # always \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们让 ai 回答一个笑话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke for you: Why couldn't the bicycle stand up by itself? Because it was two tired!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后让 ai 重复这个笑话，单个聊天场景下，ai 将不清楚之前问过的笑话，会询问这个笑话是啥，而不是重复之前的笑话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here is the joke again:\n",
      "\n",
      "Why did the scarecrow win an award?\n",
      "Because he was outstanding in his field!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke please.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation\n",
    "- Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained.\n",
    "- 我们创建两个对话 agent，这两个 agent能够相互对话并且具有记忆能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\", # 接着上一个笑话的笑点往下说笑话\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Are you ready for some comedy gold? Let's do this!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Sounds good, Cathy! Let's jump right in. So, why did the scarecrow win an award?\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Cathy, that's a good one! Your turn.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some results\n",
    "You can print out:\n",
    "\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出聊天历史记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Hey Joe! Are you ready for some comedy gold? Let's do this!\",\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'},\n",
      " {'content': \"Sounds good, Cathy! Let's jump right in. So, why did the \"\n",
      "             'scarecrow win an award?\\n'\n",
      "             'Because he was outstanding in his field!',\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Cathy, that's a good one! Your turn.\",\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "资源消耗统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'total_cost': 0},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 58,\n",
      "                                                             'cost': 0.00019049999999999997,\n",
      "                                                             'prompt_tokens': 207,\n",
      "                                                             'total_tokens': 265},\n",
      "                                      'total_cost': 0.00019049999999999997}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对话摘要生成（通常可能是最后一句话）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Cathy, that's a good one! Your turn.\"\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary_method和summary_prompt参数会在最后调用，作为 promot 对前面的对话内容进行更的总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Are you ready for some comedy gold? Let's do this!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Sounds good, Cathy! Let's jump right in. So, why did the scarecrow win an award?\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Cathy, that's a good one! Your turn.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Joe and Cathy are cracking jokes and having fun with each other. Joe started '\n",
      " \"with a scarecrow joke, and now it's Cathy's turn to share a joke.\")\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Termination\n",
    "- Chat can be terminated using a termination conditions.\n",
    "- 如果我们不知道多少轮结束后会结束， 可以设置一些人为条件来提前控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    # 这里给大模型一个提示， 就是当你说I gotta go的时候，就直接结束会话。\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    # 这里是结束对话的条件函数，当会话中包含I gotta go，就会结束会话。\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
