{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [项目在线代码](https://github.com/ksm26/AI-Agentic-Design-Patterns-with-AutoGen/blob/main/L1_Multi-Agent_Conversation_and_Stand-up_Comedy.ipynb)\n",
    "### [视频地址](https://www.bilibili.com/video/BV1WJ4m137dk/?spm_id_from=333.788.videopod.episodes&vd_source=1d3a7b81d826789081d8b6870d4fff8e&p=2)\n",
    "### [文档](https://microsoft.github.io/autogen/0.2/docs/Getting-Started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![attachment:image.png](https://github.com/ksm26/AI-Agentic-Design-Patterns-with-AutoGen/blob/main/images/l1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/project/KG_Assist_LLM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "  {\n",
    "    \"model\": \"qwen2.5:72b-instruct-q4_0\",\n",
    "    \"base_url\": \"http://192.168.28.5:11434/v1\",\n",
    "    \"api_key\": \"ollama\",\n",
    "    \"price\": [0, 0], \n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用openai本地"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://192.168.28.5:8178/v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"qwen\",\n",
    "        \"api_key\": \"sk-xxx\",\n",
    "        \"api_type\": \"openai\",\n",
    "        \"base_url\": \"http://192.168.28.5:8178/v1\",\n",
    "        \"n\": 1,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"price\": [0, 0], \n",
    "        \"default_headers\": {\n",
    "            \"Content-types\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer xxxx\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用 openai-hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"api_key\": \"hk-xxx\",\n",
    "        \"api_type\": \"openai\",\n",
    "        \"base_url\": \"https://api.openai-hk.com/v1\",\n",
    "        \"n\": 1,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"price\": [0, 0], \n",
    "        \"default_headers\": {\n",
    "            \"Content-types\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer hk-xxx\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt4free\n",
    "\n",
    "- models: https://github.com/xtekky/gpt4free/blob/main/docs/providers-and-models.md#models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_list = [\n",
    "#     {\n",
    "#         \"model\": \"gpt-3.5-turbo\",\n",
    "#         \"api_key\": \"\",\n",
    "#         \"api_type\": \"openai\",\n",
    "#         \"base_url\": \"http://192.168.28.5:1337/v1\",\n",
    "#         \"default_headers\": {\n",
    "#                     \"Content-types\": \"application/json\",\n",
    "#         }\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config={\"config_list\": config_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\", # always \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们让 ai 回答一个笑话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke for you:\n",
      "\n",
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two tired!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后让 ai 重复这个笑话，单个聊天场景下，ai 将不清楚之前问过的笑话，会询问这个笑话是啥，而不是重复之前的笑话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's the joke again: \n",
      "\n",
      "Why did the scarecrow win an award? Because he was outstanding in his field!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke please.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation\n",
    "- Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained.\n",
    "- 我们创建两个对话 agent，这两个 agent能够相互对话并且具有记忆能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\", # 接着上一个笑话的笑点往下说笑话\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Thanks for setting me up for some laughs. So, I recently started a new diet where I only eat food that starts with the letter \"P.\" Let me tell you, it's been a real struggle trying to find a way to fit pizza, pasta, and pancakes into every meal!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's hilarious, Cathy! It sounds like you're on the \"P\"izza, \"P\"asta, and \"P\"ancakes diet!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Cathy\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some results\n",
    "You can print out:\n",
    "\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出聊天历史记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Hey Joe! Thanks for setting me up for some laughs. So, I '\n",
      "             'recently started a new diet where I only eat food that starts '\n",
      "             'with the letter \"P.\" Let me tell you, it\\'s been a real struggle '\n",
      "             'trying to find a way to fit pizza, pasta, and pancakes into '\n",
      "             'every meal!',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'},\n",
      " {'content': 'That\\'s hilarious, Cathy! It sounds like you\\'re on the \"P\"izza, '\n",
      "             '\"P\"asta, and \"P\"ancakes diet!',\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Cathy', 'name': 'cathy', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "资源消耗统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'total_cost': 0},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 94,\n",
      "                                                             'cost': 0.0,\n",
      "                                                             'prompt_tokens': 298,\n",
      "                                                             'total_tokens': 392},\n",
      "                                      'total_cost': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对话摘要生成（通常可能是最后一句话）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Cathy'\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary_method和summary_prompt参数会在最后调用，作为 promot 对前面的对话内容进行更的总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Thanks for setting me up for some laughs. So, I recently started a new diet where I only eat food that starts with the letter \"P.\" Let me tell you, it's been a real struggle trying to find a way to fit pizza, pasta, and pancakes into every meal!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's hilarious, Cathy! It sounds like you're on the \"P\"izza, \"P\"asta, and \"P\"ancakes diet!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Cathy\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cathy is joking about being on a diet where she only eats foods that start '\n",
      " 'with the letter \"P,\" like pizza, pasta, and pancakes.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Termination\n",
    "- Chat can be terminated using a termination conditions.\n",
    "- 如果我们不知道多少轮结束后会结束， 可以设置一些人为条件来提前控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    # 这里给大模型一个提示， 就是当你说I gotta go的时候，就直接结束会话。\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    # 这里是结束对话的条件函数，当会话中包含I gotta go，就会结束会话。\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Ready to laugh? Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a good one, Cathy! Here's one for you: Why did the math book look sad? Because it had too many problems.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, I love it, Joe! Here's another one for you: Why did the tomato turn red? Because it saw the salad dressing!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a classic, Cathy! Here's one more for you: Why couldn't the bicycle stand up by itself? Because it was two tired!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a good one, Joe! Thanks for sharing. I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "The last joke we talked about was \"Why couldn't the bicycle stand up by itself? Because it was two tired!\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's right! Thanks for reminding me, Joe. I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
